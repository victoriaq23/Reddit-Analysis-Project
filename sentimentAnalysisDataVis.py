#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Aug  2 11:35:04 2021
This file is used to create a data visualization based on prediction results
generated by running the pre-trained NLTK sentiment analysis model VADER on
Reddit data files
@author: r21vxquin
"""

import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

import pandas as pd
import csv 
import re
from nltk.corpus import stopwords

import plotly
import plotly.io as pio
import plotly.express as px
import os
import csv
#import numpy as nd
pio.renderers.default = "firefox"

nltk.download('vader_lexicon')
sentimentAnalyzer = SentimentIntensityAnalyzer()

def preprocess_text(sen):
    # Remove punctuations and numbers
    sentence = re.sub('[^a-zA-Z]', ' ', str(sen))

    # Single character removalkeras.layers.merge
    sentence = re.sub(r"\s+[a-zA-Z]\s+", ' ', str(sentence))

    # Removing multiple spaces
    sentence = re.sub(r'\s+', ' ', str(sentence))
    
    tempSentenceArray = sentence.split()
    newSentence = []
    #print(tempSentenceArray)
    for word in tempSentenceArray:
        try:
            word.encode(encoding='utf-8').decode('ascii') #removes foreign characters
        except UnicodeDecodeError:
            continue
        else:
            if word not in stopwords.words('english'):
                newSentence.append(word.lower())
            #print(newSentence)
    if len(newSentence) >= 1:
        sentence = ' '.join(str(word) for word in newSentence)
    #print(sentence)
    return sentence

def loadValues(inputPath):
    # initialize the list of column names in the CSV file and then
	# load it using Pandas
    allText = []
    with open(inputPath + '.csv', 'r') as csvfile:
        allText = csvfile.read()
        allTextArray = allText.split(',')
        allData = []
        for text in allTextArray:
            #print(text)
            processed_text = preprocess_text([text])
            #print(processed_text)
            allData.append(processed_text)
    return allData

def analyzeSentiment(allData):
    result = []
    for text in allData:
        #for text in array:
        print(text)
        score = sentimentAnalyzer.polarity_scores(text)
        result.append(score)
        print(score)
    return result

def analyzeFromFile(filename):
    inputPath = '/mnt/linuxlab/home/r21vxquin/reddit-data-collector/redditData/'
    textData = loadValues(inputPath + filename)
    result = analyzeSentiment(textData)
    if 'Posts' in filename:
        endIndex = filename.find('Posts')
    else:
        endIndex = filename.find('Comments')
    subredditName = filename[7:endIndex]
    month = filename[:3]
    year = filename[3:7]
    outputPath = '/mnt/linuxlab/home/r21vxquin/reddit-data-collector/OutputData/sentimentData2.csv'
    with open(outputPath, 'a') as outputFile:
        for weightDict in result:
            weight = weightDict['compound']
            print(subredditName + ',' + str(weight) + ',' + month + ',' + year)
            outputFile.write('\n' + subredditName + ',')
            outputFile.write(str(weight) + ',')
            outputFile.write(month + ',' + year)
    outputFile.close()
    weightSum = 0
    numDatapoints = 0
    for weightDict in result:
        weight = weightDict['compound']
        weightSum += weight
        numDatapoints += 1
    average = weightSum / numDatapoints
    
    outputPathAverages = '/mnt/linuxlab/home/r21vxquin/reddit-data-collector/OutputData/sentimentDataAverages.csv'
    with open(outputPathAverages, 'a') as outputfile:
        outputfile.write('\n' + subredditName + ',' + str(average) + ',' + str(month) + ',' + str(year))
    outputfile.close()
    print('file updated')



def createGraphAllAverages(inputFile):
    long_df = pd.read_csv(inputFile)
    # fig = px.scatter(long_df, y="subreddit", x="score", color='score', color_continuous_scale='Bluered',
    #                                                   title="Sentiment Analysis of Reddit Data")
    fig = px.bar(long_df, x="subreddit", y="average score", color='average score', color_continuous_scale='Bluered', title="Sentiment Analysis of Reddit Data")
    fig.show()
    
createGraphAllAverages('/mnt/linuxlab/home/r21vxquin/reddit-data-collector/OutputData/sentimentDataAverages.csv')
